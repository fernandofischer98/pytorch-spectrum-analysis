{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75de1f0b",
   "metadata": {},
   "source": [
    "# 2.- SMILES string from IR spectra, simple encoder decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2c553f",
   "metadata": {},
   "source": [
    "We are going to build an algortihm that will translate a given IR spectrum to a SMILES sequence. The algorithm is based on the common Encoder Decoder structure. This algorithm is highly based on Ben Trevetts work https://github.com/bentrevett/pytorch-seq2seq \"1 - Sequence to Sequence Learning with Neural Networks\". The main deviation from the paper he based his algorithm on, is that instead of using a Recurrent Neural Network Encoder, we will use a Convolutional Encoder, mainly because we had promising results in our previous algorithm.\n",
    "\n",
    "It is important to mention that even though this algorithm converges, a very high accuracy shouldn't be expected. Besides using a small very small dataset, the IR spectrum has never been known to have all the information needed to generate a full molecular structure. \n",
    "\n",
    "If you have any suggestions, your feedback would be appreciated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d5647b",
   "metadata": {},
   "source": [
    "The database can be purchased here https://www.nist.gov/srd/nist-standard-reference-database-35. It contains 5308 compound IR spectrums.\n",
    "\n",
    "SMILES or \"Simplified molecular-input line-entry system\" is a representation of molecular identity. All molecules identities were converted to this format using rdkit. The use of rdkit for this conversion is not included in this file.\n",
    "\n",
    "An example: \n",
    "\n",
    "![alternative text](./assets/molecule 1 with smiles.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a92409",
   "metadata": {},
   "source": [
    "The algorithms structure is the following:\n",
    "\n",
    "![alternative text](./assets/Global Arqui.png)\n",
    "\n",
    "In essence, a spectrum is encrypted in to a vector containing the necessary information readily available for a decoder funciton to decode it.\n",
    "\n",
    "Each component and its respective mechanism will be shown in detail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ff9c07",
   "metadata": {},
   "source": [
    "Importing a few libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9a79781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e19ae6",
   "metadata": {},
   "source": [
    "Setting our device to GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f53f6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9789c907",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8eeb4a",
   "metadata": {},
   "source": [
    "The dataset is unfortunately not mine so i can't post it. It can be purchased in its raw form from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2476f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle('df_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d615f683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAS</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>3846</th>\n",
       "      <th>3842</th>\n",
       "      <th>3838</th>\n",
       "      <th>3834</th>\n",
       "      <th>3830</th>\n",
       "      <th>3826</th>\n",
       "      <th>3822</th>\n",
       "      <th>3818</th>\n",
       "      <th>...</th>\n",
       "      <th>586</th>\n",
       "      <th>582</th>\n",
       "      <th>578</th>\n",
       "      <th>574</th>\n",
       "      <th>570</th>\n",
       "      <th>566</th>\n",
       "      <th>562</th>\n",
       "      <th>558</th>\n",
       "      <th>554</th>\n",
       "      <th>550</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100-02-7</td>\n",
       "      <td>O=[N+]([O-])c1ccc(O)cc1</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100-06-1</td>\n",
       "      <td>COc1ccc(C(C)=O)cc1</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>0.005106</td>\n",
       "      <td>0.005365</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>0.005145</td>\n",
       "      <td>0.004606</td>\n",
       "      <td>0.003925</td>\n",
       "      <td>0.003209</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>0.00124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100-10-7</td>\n",
       "      <td>CN(C)c1ccc(C=O)cc1</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.00014</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00049</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.00016</td>\n",
       "      <td>0.000336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100-11-8</td>\n",
       "      <td>O=[N+]([O-])c1ccc(CBr)cc1</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100-14-1</td>\n",
       "      <td>O=[N+]([O-])c1ccc(CCl)cc1</td>\n",
       "      <td>0.00022</td>\n",
       "      <td>0.00017</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>0.00014</td>\n",
       "      <td>0.00014</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00027</td>\n",
       "      <td>0.00019</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00016</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.00028</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00023</td>\n",
       "      <td>0.00022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102</th>\n",
       "      <td>99-96-7</td>\n",
       "      <td>O=C(O)c1ccc(O)cc1</td>\n",
       "      <td>0.003148</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127616</td>\n",
       "      <td>0.084993</td>\n",
       "      <td>0.059495</td>\n",
       "      <td>0.065099</td>\n",
       "      <td>0.077627</td>\n",
       "      <td>0.065791</td>\n",
       "      <td>0.054962</td>\n",
       "      <td>0.051751</td>\n",
       "      <td>0.042937</td>\n",
       "      <td>0.03853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>99-97-8</td>\n",
       "      <td>Cc1ccc(N(C)C)cc1</td>\n",
       "      <td>0.006146</td>\n",
       "      <td>0.006086</td>\n",
       "      <td>0.007893</td>\n",
       "      <td>0.005905</td>\n",
       "      <td>0.005182</td>\n",
       "      <td>0.005724</td>\n",
       "      <td>0.00482</td>\n",
       "      <td>0.007291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007713</td>\n",
       "      <td>0.004037</td>\n",
       "      <td>0.00711</td>\n",
       "      <td>0.014039</td>\n",
       "      <td>0.017654</td>\n",
       "      <td>0.011147</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.015606</td>\n",
       "      <td>0.01904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>99-99-0</td>\n",
       "      <td>Cc1ccc([N+](=O)[O-])cc1</td>\n",
       "      <td>0.005459</td>\n",
       "      <td>0.00234</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.005654</td>\n",
       "      <td>0.005459</td>\n",
       "      <td>0.004485</td>\n",
       "      <td>0.006044</td>\n",
       "      <td>0.00351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010724</td>\n",
       "      <td>0.00351</td>\n",
       "      <td>0.006434</td>\n",
       "      <td>0.005849</td>\n",
       "      <td>0.007019</td>\n",
       "      <td>0.00117</td>\n",
       "      <td>0.004485</td>\n",
       "      <td>0.00156</td>\n",
       "      <td>0.005069</td>\n",
       "      <td>0.004485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>999-21-3</td>\n",
       "      <td>C=CCOC(=O)/C=C\\C(=O)OCC=C</td>\n",
       "      <td>0.001788</td>\n",
       "      <td>0.003088</td>\n",
       "      <td>0.001463</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.003251</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031531</td>\n",
       "      <td>0.031043</td>\n",
       "      <td>0.029256</td>\n",
       "      <td>0.020966</td>\n",
       "      <td>0.019016</td>\n",
       "      <td>0.025192</td>\n",
       "      <td>0.026167</td>\n",
       "      <td>0.028768</td>\n",
       "      <td>0.028443</td>\n",
       "      <td>0.023242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3107</th>\n",
       "      <td>999-55-3</td>\n",
       "      <td>C=CCOC(=O)C=C</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.001506</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>0.002473</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.002904</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009033</td>\n",
       "      <td>0.009894</td>\n",
       "      <td>0.011937</td>\n",
       "      <td>0.009464</td>\n",
       "      <td>0.009571</td>\n",
       "      <td>0.010431</td>\n",
       "      <td>0.010216</td>\n",
       "      <td>0.010969</td>\n",
       "      <td>0.01355</td>\n",
       "      <td>0.01269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4836 rows Ã— 827 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           CAS                     SMILES      3846      3842      3838  \\\n",
       "0     100-02-7    O=[N+]([O-])c1ccc(O)cc1  0.000122  0.000098  0.000091   \n",
       "1     100-06-1         COc1ccc(C(C)=O)cc1  0.000147  0.000152  0.000176   \n",
       "2     100-10-7         CN(C)c1ccc(C=O)cc1  0.000182  0.000166   0.00014   \n",
       "3     100-11-8  O=[N+]([O-])c1ccc(CBr)cc1    0.0002  0.000165  0.000139   \n",
       "4     100-14-1  O=[N+]([O-])c1ccc(CCl)cc1   0.00022   0.00017   0.00012   \n",
       "...        ...                        ...       ...       ...       ...   \n",
       "3102   99-96-7          O=C(O)c1ccc(O)cc1  0.003148  0.000441  0.002392   \n",
       "3103   99-97-8           Cc1ccc(N(C)C)cc1  0.006146  0.006086  0.007893   \n",
       "3104   99-99-0    Cc1ccc([N+](=O)[O-])cc1  0.005459   0.00234  0.004875   \n",
       "3106  999-21-3  C=CCOC(=O)/C=C\\C(=O)OCC=C  0.001788  0.003088  0.001463   \n",
       "3107  999-55-3              C=CCOC(=O)C=C  0.000538  0.001506  0.002258   \n",
       "\n",
       "          3834      3830      3826      3822      3818  ...       586  \\\n",
       "0      0.00007  0.000038  0.000055  0.000079  0.000072  ...  0.000434   \n",
       "1     0.000132  0.000078  0.000054  0.000054  0.000069  ...  0.004322   \n",
       "2     0.000073  0.000064  0.000048  0.000088  0.000105  ...   0.00049   \n",
       "3     0.000131  0.000113  0.000157  0.000183  0.000148  ...  0.001296   \n",
       "4      0.00014   0.00014   0.00008    0.0001   0.00012  ...   0.00027   \n",
       "...        ...       ...       ...       ...       ...  ...       ...   \n",
       "3102  0.002015  0.001133  0.001511  0.003903  0.000252  ...  0.127616   \n",
       "3103  0.005905  0.005182  0.005724   0.00482  0.007291  ...  0.007713   \n",
       "3104  0.005654  0.005459  0.004485  0.006044   0.00351  ...  0.010724   \n",
       "3106    0.0026  0.003251  0.001138  0.003738  0.002926  ...  0.031531   \n",
       "3107  0.002473  0.001613  0.002904  0.000968  0.001828  ...  0.009033   \n",
       "\n",
       "           582       578       574       570       566       562       558  \\\n",
       "0     0.000434  0.000449  0.000475  0.000406  0.000307  0.000293  0.000175   \n",
       "1     0.005106  0.005365  0.005356  0.005145  0.004606  0.003925  0.003209   \n",
       "2     0.000255  0.000073   0.00008  0.000126  0.000182  0.000198  0.000085   \n",
       "3     0.000826  0.000513  0.000313  0.000191  0.000052  0.000035  0.000009   \n",
       "4      0.00019   0.00012   0.00002   0.00016    0.0003   0.00028    0.0002   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3102  0.084993  0.059495  0.065099  0.077627  0.065791  0.054962  0.051751   \n",
       "3103  0.004037   0.00711  0.014039  0.017654  0.011147  0.018558  0.001024   \n",
       "3104   0.00351  0.006434  0.005849  0.007019   0.00117  0.004485   0.00156   \n",
       "3106  0.031043  0.029256  0.020966  0.019016  0.025192  0.026167  0.028768   \n",
       "3107  0.009894  0.011937  0.009464  0.009571  0.010431  0.010216  0.010969   \n",
       "\n",
       "           554       550  \n",
       "0     0.000146  0.000278  \n",
       "1     0.002768   0.00124  \n",
       "2      0.00016  0.000336  \n",
       "3     0.000209  0.000391  \n",
       "4      0.00023   0.00022  \n",
       "...        ...       ...  \n",
       "3102  0.042937   0.03853  \n",
       "3103  0.015606   0.01904  \n",
       "3104  0.005069  0.004485  \n",
       "3106  0.028443  0.023242  \n",
       "3107   0.01355   0.01269  \n",
       "\n",
       "[4836 rows x 827 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fdca5d",
   "metadata": {},
   "source": [
    "Define a function that will take the smiles string as input and output a list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52af6fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(smiles_string):\n",
    "    #tokens=re.findall(\".\",smiles_string)\n",
    "    tokens=re.findall(\"\\[.+?]|Br|Cl|.\",smiles_string)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaca18b3",
   "metadata": {},
   "source": [
    "Remove strings containing more than 20 tokens. Just because GRU's can be limited when having to deal with too many time steps. \n",
    "For this, we will create a column that will indicate if a given row contains a smiles string containing more than 20 tokens. Later we delete the rows that do and we delete the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "400c2515",
   "metadata": {},
   "outputs": [],
   "source": [
    "over_20=[]\n",
    "for x in range(4836):\n",
    "    if len(tokenize(df.iloc[x,1]))>20:\n",
    "        over_20.append(1)\n",
    "    else:\n",
    "        over_20.append(0)\n",
    "        \n",
    "df.insert(1, 'Over_20', over_20, True)\n",
    "\n",
    "df=df[df.Over_20!=1]\n",
    "df=df.drop(columns={'Over_20'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe62a12",
   "metadata": {},
   "source": [
    "Save absorbance values to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c615ca4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "absor=[]\n",
    "for x in range(len(df)):\n",
    "    ab_values=[]\n",
    "    for y in range(2,827):\n",
    "        ab_values.append(df.iloc[x,y]) #1/(10**(df.iloc[x,y]))\n",
    "    absor.append(ab_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237e10b1",
   "metadata": {},
   "source": [
    "For each smiles string, a '<sos>' token is appended at the beggining, a '<eos>' token at the end, and as many 'padding' tokens as needed to make the length of each tokens list for each compound the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee837cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens=[]\n",
    "unique_tokens.append('<sos>')\n",
    "unique_tokens.append('<eos>')\n",
    "unique_tokens.append('padding') #this is padding\n",
    "\n",
    "for x in range(len(df)):\n",
    "    for token in tokenize(df.iloc[x,1]):\n",
    "        if token not in unique_tokens:\n",
    "            unique_tokens.append(token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ea90fe1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " '<eos>',\n",
       " 'padding',\n",
       " 'O',\n",
       " '=',\n",
       " '[N+]',\n",
       " '(',\n",
       " '[O-]',\n",
       " ')',\n",
       " 'c',\n",
       " '1',\n",
       " 'C',\n",
       " 'N',\n",
       " 'Br',\n",
       " 'Cl',\n",
       " '#',\n",
       " 'n',\n",
       " '2',\n",
       " '3',\n",
       " '/',\n",
       " 'S',\n",
       " '-',\n",
       " '\\\\',\n",
       " '[C@@H]',\n",
       " '[nH]',\n",
       " 'o',\n",
       " 'P',\n",
       " '[C@H]',\n",
       " 'I',\n",
       " '.',\n",
       " 'F',\n",
       " 's',\n",
       " '[O]',\n",
       " '[Si]',\n",
       " '[n+]',\n",
       " '[N-]',\n",
       " '[Sn]',\n",
       " '[Hg]',\n",
       " '[se]',\n",
       " 'B',\n",
       " '[C]',\n",
       " '[PH]',\n",
       " '[SiH2]',\n",
       " '[GeH4]',\n",
       " '[2H]']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8c461888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8c13e9",
   "metadata": {},
   "source": [
    "Now each molecules smiles string will be converted to a one-hot-encoded representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b4e225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We first generate len(unique_tokens) one-hot-encoddings\n",
    " \n",
    "one_hotted_tokens=F.one_hot(torch.arange(0,len(unique_tokens)), num_classes=len(unique_tokens))\n",
    "\n",
    "#Then convert each token for each sentence in to one hot encoded and also append <sos>, <eos> and padding accordingly\n",
    "smiles=[]\n",
    "for x in range(len(df)):\n",
    "    scrap=[]\n",
    "    scrap.append(one_hotted_tokens[0].numpy()) #first append start of sentence\n",
    "    \n",
    "    \n",
    "    for token in tokenize(df.iloc[x,1]):\n",
    "        \n",
    "        scrap.append(one_hotted_tokens[unique_tokens.index(token)].numpy())#token\n",
    "    scrap.append(one_hotted_tokens[1].numpy())#<eos>\n",
    "        \n",
    "    while len(scrap)<=21:\n",
    "        scrap.append(one_hotted_tokens[2].numpy())#padding\n",
    "                     \n",
    "    smiles.append(scrap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85576be",
   "metadata": {},
   "source": [
    "So for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "06791b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this smiles string  O=[N+]([O-])c1ccc(O)cc1 \n",
      "was converted to:  [array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0], dtype=int64), array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0], dtype=int64), array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0], dtype=int64), array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0], dtype=int64), array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0], dtype=int64), array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0], dtype=int64), array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0], dtype=int64), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0], dtype=int64), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0], dtype=int64), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0], dtype=int64), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0], dtype=int64), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0], dtype=int64), array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0], dtype=int64), array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0], dtype=int64), array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0], dtype=int64), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0], dtype=int64), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0], dtype=int64), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0], dtype=int64), array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0], dtype=int64), array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0], dtype=int64), array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0], dtype=int64), array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "print('this smiles string ', df.iloc[0,1], '\\nwas converted to: ', smiles[0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0766630d",
   "metadata": {},
   "source": [
    "Notice how the first array has a 1 and then only zeros. This array represents the '<sos>' token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5674e4",
   "metadata": {},
   "source": [
    "Print the length of all one-hot-encoded smiles strings: (will be the same for all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88bff37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "print(len(smiles[0]))\n",
    "print(len(smiles[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef8d72d",
   "metadata": {},
   "source": [
    "Define a dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f8b1723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, smiles, absorbances):\n",
    "        self.x=torch.tensor(absorbances).view(-1,1,825)\n",
    "        self.y=torch.tensor(smiles).float() #FloatTensor\n",
    "        self.len=len(absorbances)\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231240a9",
   "metadata": {},
   "source": [
    "Instance an object of class dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d7865065",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=dataset(smiles, absor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bfb54f",
   "metadata": {},
   "source": [
    "Split the data into training set and validation set. Note we havent created a test set. This can be considered as not good practice sometimes, due to the overfiiting effect a human can have when tunning hyperparameters. We havent added it because our dataset is small. You are welcome to try either adding a test set or generating various splits of train/val and see how the algo trains on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7d316f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set= torch.utils.data.random_split(data, [3200, 493], generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e816bf0e",
   "metadata": {},
   "source": [
    "Visualize source and target on the train_set, for a batch size of 60 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f90608f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absorbance tensor([[[8.7119e-03, 6.9695e-03, 6.9695e-03,  ..., 1.5546e-01,\n",
      "          1.4326e-01, 1.5604e-01]],\n",
      "\n",
      "        [[2.4960e-04, 2.0410e-04, 2.1450e-04,  ..., 1.5600e-04,\n",
      "          2.1450e-04, 2.3270e-04]],\n",
      "\n",
      "        [[8.1900e-05, 8.1900e-05, 6.6300e-05,  ..., 8.1900e-05,\n",
      "          4.2900e-05, 1.0140e-04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[3.2700e-04, 1.9620e-04, 2.8340e-04,  ..., 1.3080e-04,\n",
      "          1.0900e-04, 6.5400e-05]],\n",
      "\n",
      "        [[2.0954e-02, 2.1662e-02, 2.4777e-02,  ..., 8.0702e-03,\n",
      "          8.2118e-03, 9.4861e-03]],\n",
      "\n",
      "        [[1.9140e-04, 2.7060e-04, 2.9370e-04,  ..., 3.1350e-04,\n",
      "          2.0790e-04, 9.5700e-05]]])\n",
      "absorbance shape torch.Size([60, 1, 825])\n",
      "squeezed torch.Size([60, 825])\n",
      "smiles tensor([[[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 1.,  ..., 0., 0., 0.]]])\n",
      "smiles shape torch.Size([60, 22, 45])\n"
     ]
    }
   ],
   "source": [
    "train_loader=DataLoader(dataset=train_set, batch_size=60)\n",
    "val_loader=DataLoader(dataset=val_set, batch_size=30)\n",
    "\n",
    "#print an example\n",
    "\n",
    "print('absorbance', list(train_loader)[0][0])\n",
    "print('absorbance shape', list(train_loader)[0][0].shape)\n",
    "print('squeezed', list(train_loader)[0][0].squeeze(1).shape)\n",
    "print('smiles', list(train_loader)[0][1])\n",
    "\n",
    "print('smiles shape', list(train_loader)[0][1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611ed785",
   "metadata": {},
   "source": [
    "# Neural System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7483491f",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "\n",
    "\n",
    "![alternative text](./assets/Arqui 1.png)\n",
    "![alternative text](./assets/Arqui 2.png)\n",
    "\n",
    "The Encoders goal is to translate the spectrum in to a list of numbers (the code). The code will later on be \"decoded\" by the decoder into a SMILES sequence.\n",
    "\n",
    "This encoder is very basic, and it uses a whole lot of dropout. \n",
    "\n",
    "Given a list of values containing the absorbances of a given compound for a range of wavelengths, the algo will first perform a 1D convolution operation. \n",
    "\n",
    "#### 1st Convolution: \n",
    "\n",
    "With a specified stride(jump) the Kernels are sweeped through the spectrum to generate n Activation maps, where n is also the number of output channels and the number of kernels. \n",
    "\n",
    "#### 1st Max pooling:\n",
    "\n",
    "The poolings kernel is sweeped though the Activation maps selecting the max value of each set of number from each map per stride.\n",
    "\n",
    "#### 2nd Convolution:\n",
    "\n",
    "Now the convlution has more than one input channel, so the operation is a little more complicated. m output channels will be generated. For each output channel (each activation map), there are n kernels. For the first activation map, n different kernels are swept though each pooled vector, generating one braket of operations in the diagram. For the next activation map, a different set of n kernerls are swet though and so forth. Fundamentally there is one kernel per pooled vector per output map, so n*m kernels.\n",
    "\n",
    "#### 2nd Max pooling:\n",
    "\n",
    "A Max pooled vector is generated from each activation map, same as in 1st Max pooling.\n",
    "\n",
    "#### Concatenation:\n",
    "\n",
    "M pooled vectors are concatenated\n",
    "\n",
    "#### 1st Linear:\n",
    "\n",
    "For the first hidden value Each value of the concatenated Pooled vector is multiplied by a weight, added together and a bias is added as well. Subsequently the resulting value goes through an activation function (ReLU). For the next hidden values a new set of weights and bias is applied, and all passed through ReLU as well. \n",
    "\n",
    "#### 2nd Linear:\n",
    "\n",
    "For the first Code vector value, Each hidden value is multiplied by a weight, added together and a bias is added as well. Subsequently the resulting value goes through an activation function (ReLU). For the next hidden values a new set of weights and bias is applied and all passed though ReLU. Code is just a list of numbers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "031d3dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, out_1, out_2, conv_out_size, out_3, p, code_dim):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.cnn1=nn.Conv1d(in_channels=1, out_channels=out_1, kernel_size=4, stride=1, padding=0)\n",
    "        self.maxpool1=nn.MaxPool1d(kernel_size=3, stride=2)\n",
    "        \n",
    "        self.cnn2=nn.Conv1d(in_channels=out_1, out_channels=out_2, kernel_size=3, stride=1, padding=0)\n",
    "        self.maxpool2=nn.MaxPool1d(kernel_size=3, stride=2)\n",
    "        \n",
    "        self.dropout=nn.Dropout(p)\n",
    "        self.linear=nn.Linear(conv_out_size*out_2, out_3) \n",
    "        self.dropout2=nn.Dropout(p=0.5)\n",
    "        self.linear2=nn.Linear(out_3, code_dim)\n",
    "        self.dropout3=nn.Dropout(p=0.5)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #1st conv and 1st pooling\n",
    "        \n",
    "        x=self.cnn1(x)\n",
    "        x=torch.relu(x)\n",
    "        x=self.maxpool1(x)\n",
    "        \n",
    "        #2nd conv and 2nd pooling\n",
    "        \n",
    "        x=self.cnn2(x)\n",
    "        x=torch.relu(x)\n",
    "        x=self.maxpool2(x)\n",
    "        \n",
    "        #Concatting\n",
    "        \n",
    "        x=x.view(x.size(0), -1)\n",
    "        x=self.dropout(x)\n",
    "        \n",
    "        #first linear\n",
    "        \n",
    "        x=self.linear(x)\n",
    "        x=torch.relu(x)\n",
    "        x=self.dropout2(x)\n",
    "        \n",
    "        #2nd Linear\n",
    "        \n",
    "        x=self.linear2(x) \n",
    "        x=torch.relu(x)\n",
    "        x=self.dropout3(x)\n",
    "        \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e856c467",
   "metadata": {},
   "source": [
    "Define a function that will comput the output size of convolutional or pooling layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5a4ff728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_output_size(Lin, kernel_size=1, stride=1, pad=0, dilation=1):\n",
    "    from math import floor\n",
    "    size = floor( ((Lin + (2 * pad) - ( dilation * (kernel_size - 1) ) - 1 )/ stride) + 1)\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bad420a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size=3\n",
    "tamano_stride=1\n",
    "\n",
    "o1=conv_output_size(825, kernel_size=4, stride=1)\n",
    "o2=conv_output_size(o1, kernel_size=3, stride=2)\n",
    "\n",
    "o3=conv_output_size(o2, kernel_size=3, stride=1)\n",
    "o4=conv_output_size(o3, kernel_size=3, stride=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb418023",
   "metadata": {},
   "source": [
    "Just to visualize the output Create an instance of class encoder and input the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2179a72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code:  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.2907, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.1773, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2628, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "\n",
      "\n",
      "code shape:  torch.Size([60, 400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferna\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "encoder=Encoder(out_1=8, out_2=8, conv_out_size=o4, out_3=1000, p=0.5, code_dim=400)\n",
    "\n",
    "print('code: ', encoder(list(train_loader)[0][0]))\n",
    "print('\\n')\n",
    "print('code shape: ', encoder(list(train_loader)[0][0]).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4f1d68",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37252755",
   "metadata": {},
   "source": [
    "![alternative text](./assets/Arqui 3.png)\n",
    "\n",
    "The decoder is nothing but a recurrent unit with one time step, meaning we will always input a sequence length of 1.\n",
    "\n",
    "The decoder used in the code is a GRU, the one represented by the graph resembles a standard RNN, i didn't add the equations for a GRU because they are somewhat extensive, but in essence a recurrent unit takes a previous hidden and combines it with the current time step input to generate a new hidden state, and so forth. \n",
    "\n",
    "So following the sequence:\n",
    "\n",
    "#### Embedding lookup\n",
    "\n",
    "The input is the previous token (this is a vector of len (one-hot-encodding)). Argmax retrieves the index of the highest number of said vector. This index (single number), is the input to the embedding lookup function. The embedding lookup function will locate the embedding vector for this index.  \n",
    "\n",
    "#### Recurrent Unit\n",
    "\n",
    "The reason why we use a one time step recurrent unit, is because the input in each timestep is the previous timestep output, so not only the previous hidden, but the actual output as well. It is not possible to let the GRU create timestep outputs without timestep inputs. \n",
    "\n",
    "So with the embedding and previous hidden, new hidden is computed. New hidden is passed through 2 hidden layers with ReLU activations, and the prediction vector is generated. \n",
    "\n",
    "Saying previous hidden may be confusing, in the spectra2sequence diagram and code the mechanisms will seem more clear. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3a35b7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, size_of_vocab, embedding_dim, code_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "    \n",
    "        self.embedding=nn.Embedding(size_of_vocab, embedding_dim)\n",
    "        self.gru=nn.GRU(input_size=embedding_dim, hidden_size=code_dim, batch_first=True)\n",
    "        self.linear=nn.Linear(code_dim, 150) #code_dim is same size as hidden dim\n",
    "        self.linear2=nn.Linear(150, size_of_vocab)\n",
    "        self.dropout=nn.Dropout(p=0.5)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        \n",
    "        input=input.argmax(1)\n",
    "\n",
    "        #Size([batch_size])\n",
    "\n",
    "        embedded=self.dropout(self.embedding(input)) #(batch_size, Embedding_dim)\n",
    "\n",
    "        #Size([batch_size, emb_dim])\n",
    "        \n",
    "        embedded=embedded.unsqueeze(0).permute(1,0,2) #(batch_size, seq_len, embedding_dim)\n",
    "\n",
    "        #Size([batch_size, 1, emb_dim])\n",
    "\n",
    "        output, h_n=self.gru(embedded, hidden) \n",
    "\n",
    "        #Size([1, bathc_size, code])\n",
    "        \n",
    "        prediction=self.dropout(torch.relu(self.linear(h_n)))\n",
    "\n",
    "        #Size([1, batch_size, 150])\n",
    "        \n",
    "        prediction=self.linear2(prediction) \n",
    "\n",
    "        #Size([1, batch_size, len(unique_tokens)])\n",
    "        \n",
    "\n",
    "        \n",
    "        return prediction, h_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a360b026",
   "metadata": {},
   "source": [
    "Visualize the output for first time step (assuming a code dimension of 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6b2394d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder=Decoder(size_of_vocab=len(unique_tokens), embedding_dim=10, code_dim=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4fd438a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code tensor([[[0.0000, 0.1733, 0.0000,  ..., 0.0000, 0.0809, 0.0000],\n",
      "         [0.0000, 0.1182, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0530, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0109, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       grad_fn=<UnsqueezeBackward0>)\n",
      "code shape torch.Size([1, 60, 400])\n",
      "input tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]])\n",
      "input shape torch.Size([60, 45])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Time step 1\n",
    "\n",
    "hid=encoder(list(train_loader)[0][0]).unsqueeze(0)\n",
    "print('code', hid)\n",
    "print('code shape', hid.shape)\n",
    "\n",
    "inputs=list(train_loader)[0][1][:,0]\n",
    "print('input', inputs)\n",
    "print('input shape', inputs.shape)\n",
    "\n",
    "decoder(list(train_loader)[0][1][:,0], hid) #input is embedding(unique_tokens.index(<sos>))\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af64a7d",
   "metadata": {},
   "source": [
    "## Spectrum 2 Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312173ea",
   "metadata": {},
   "source": [
    "![alternative text](./assets/Arqui 4.png)\n",
    "![alternative text](./assets/Arqui 5.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2eab25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
